{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T17:37:17.059124Z",
     "start_time": "2021-03-22T17:37:15.335317Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook\nNot notebook\n"
     ]
    }
   ],
   "source": [
    "import os, sys, argparse, importlib, time, inspect, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    print('Notebook')\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    print('Not notebook')\n",
    "    from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "# if len(gpu_devices) > 0:\n",
    "#     print(\"GPU detected\")\n",
    "#     tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "# else:\n",
    "#     print('No GPU detected')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import spektral\n",
    "from sklearn.preprocessing import normalize\n",
    "from spektral.data import DisjointLoader, BatchLoader, SingleLoader\n",
    "from importlib import reload\n",
    "import dev.data_load as dl\n",
    "reload(dl)\n",
    "graph_data=dl.graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/lustre/hpc/hep/chri862z/work/IceCube/from_config'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T16:42:40.609Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "os.system(\"python submit_results.py -list_databases TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'): # if on the cpu\n",
    "    model=tf.keras.models.load_model('from_config/trained_models/IceCube/Sage_sage1nonorm_10_2aauycmh')\n",
    "    model.compile()\n",
    "# batch_size=512\n",
    "# dataset=graph_data(n_data=100000,skip=int(1.4e6-1), restart=1, transform=True, angle=True, unitvec=False)\n",
    "# loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed and ready to reload\n",
      "Connecting to db-file\n",
      "Loading Muons\n",
      "Reading files\n",
      "/groups/hep/chri862z/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/groups/hep/chri862z/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RobustScaler from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]Splitting data to events\n",
      "     dom_x    dom_y    dom_z      time  charge_log10  SRTInIcePulses\n",
      "0  0.13203  0.20298  0.12828 -0.060393     -1.921554               1\n",
      "1  0.13203  0.20298  0.11126 -0.000741     -1.656923               1\n",
      "2  0.05426  0.29297  0.28626 -0.300482      0.378965               1\n",
      "3  0.05426  0.29297  0.25222 -0.288255      0.238063               1\n",
      "4  0.05426  0.29297  0.25222 -0.227862     -0.280277               1\n",
      "   energy_log10    zenith   azimuth\n",
      "0      2.437721  0.661937  1.697274\n",
      "1      2.584876  0.205041  4.291144\n",
      "2      2.476674  0.661661  1.374715\n",
      "3      2.409273  0.390813  2.876407\n",
      "4      2.356129  0.889406  2.381056\n",
      "Generating adjacency matrices\n",
      "100%|██████████| 100000/100000 [00:36<00:00, 2727.02it/s]\n",
      "Saving dataset\n",
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "batch_size=512\n",
    "dataset=graph_data(n_data=100000,skip=int(1.4e6-1), restart=1, transform=True, angle=True, unitvec=False, transform_path='db_files/muongun/transformers.pkl', db_path= 'db_files/muongun/rasmus_classification_muon_3neutrino_3mio.db')\n",
    "loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature = loader.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training = False)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "\n",
    "    return predictions, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        predictions, targets = test_step(inputs, targets)\n",
    "\n",
    "        prediction_list.append(predictions.numpy())\n",
    "        target_list.append(targets.numpy())\n",
    "        y_reco  = tf.concat(prediction_list, axis = 0).numpy()\n",
    "        y_true  = tf.concat(target_list, axis = 0)\n",
    "        y_true  = tf.cast(y_true, tf.float32).numpy()\n",
    "    return y_reco, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco, true=predict(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   energy_log10_pred  zenith_pred  azimuth_pred  zenith_sigma  azimuth_sigma\n",
       "0           2.442123     0.459739      0.154261     11.903859     131.819977\n",
       "1           2.465787     0.378621      0.698523      0.219347      30.790274\n",
       "2           2.509951     0.491649      1.775593     26.031609     157.727448\n",
       "3           2.299295     0.639824      2.637994      3.692753      21.571054\n",
       "4           2.684694     0.775960      2.771619     15.115727      54.793076"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>energy_log10_pred</th>\n      <th>zenith_pred</th>\n      <th>azimuth_pred</th>\n      <th>zenith_sigma</th>\n      <th>azimuth_sigma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.442123</td>\n      <td>0.459739</td>\n      <td>0.154261</td>\n      <td>11.903859</td>\n      <td>131.819977</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.465787</td>\n      <td>0.378621</td>\n      <td>0.698523</td>\n      <td>0.219347</td>\n      <td>30.790274</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.509951</td>\n      <td>0.491649</td>\n      <td>1.775593</td>\n      <td>26.031609</td>\n      <td>157.727448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.299295</td>\n      <td>0.639824</td>\n      <td>2.637994</td>\n      <td>3.692753</td>\n      <td>21.571054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.684694</td>\n      <td>0.775960</td>\n      <td>2.771619</td>\n      <td>15.115727</td>\n      <td>54.793076</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "reco_str=['energy_log10_pred', 'zenith_pred', 'azimuth_pred', 'zenith_sigma', 'azimuth_sigma']\n",
    "recos=pd.DataFrame(reco)\n",
    "recos.columns=reco_str\n",
    "recos.head() ### change azi/zeni sigma to real sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get event_nos through data_load (just make an extra file with event_nos)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ee7ae0cce42568ffbe792829a147e8b26e32fc5929320da4cac6b0f8a68675f6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ee7ae0cce42568ffbe792829a147e8b26e32fc5929320da4cac6b0f8a68675f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}