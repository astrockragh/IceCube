{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T17:37:17.059124Z",
     "start_time": "2021-03-22T17:37:15.335317Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook\n",
      "Not notebook\n",
      "Not notebook\n"
     ]
    }
   ],
   "source": [
    "import os, sys, argparse, importlib, time, inspect, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    print('Notebook')\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    print('Not notebook')\n",
    "    from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "# if len(gpu_devices) > 0:\n",
    "#     print(\"GPU detected\")\n",
    "#     tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "# else:\n",
    "#     print('No GPU detected')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import spektral\n",
    "from sklearn.preprocessing import normalize\n",
    "from spektral.data import DisjointLoader, BatchLoader, SingleLoader\n",
    "from importlib import reload\n",
    "import dev.data_load as dl\n",
    "reload(dl)\n",
    "graph_data=dl.graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/lustre/hpc/hep/chri862z/work/IceCube/from_config'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T16:42:40.609Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"python submit_results.py -list_databases TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'): # if on the cpu\n",
    "    model=tf.keras.models.load_model('from_config/trained_models/IceCube/Sage_sage1nonorm_10_2aauycmh')\n",
    "    model.compile()\n",
    "# batch_size=512\n",
    "# dataset=graph_data(n_data=100000,skip=int(1.4e6-1), restart=1, transform=True, angle=True, unitvec=False)\n",
    "# loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed and ready to reload\n",
      "Connecting to db-file\n",
      "Loading Muons\n",
      "Reading files\n",
      "/groups/hep/chri862z/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/groups/hep/chri862z/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RobustScaler from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "Splitting data to events\n",
      "  0%|          | 1/100000 [00:00<3:34:15,  7.78it/s]     dom_x    dom_y    dom_z      time  charge_log10  SRTInIcePulses\n",
      "0  0.13203  0.20298  0.12828 -0.060393     -1.921554               1\n",
      "1  0.13203  0.20298  0.11126 -0.000741     -1.656923               1\n",
      "2  0.05426  0.29297  0.28626 -0.300482      0.378965               1\n",
      "3  0.05426  0.29297  0.25222 -0.288255      0.238063               1\n",
      "4  0.05426  0.29297  0.25222 -0.227862     -0.280277               1\n",
      "   energy_log10    zenith   azimuth\n",
      "0      2.437721  0.661937  1.697274\n",
      "1      2.584876  0.205041  4.291144\n",
      "2      2.476674  0.661661  1.374715\n",
      "3      2.409273  0.390813  2.876407\n",
      "4      2.356129  0.889406  2.381056\n",
      "Generating adjacency matrices\n",
      "100%|██████████| 100000/100000 [00:37<00:00, 2698.11it/s]\n",
      "Saving dataset\n",
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "batch_size=512\n",
    "dataset=graph_data(n_data=100000,skip=int(1.4e6-1), restart=1, transform=True, angle=True, unitvec=False, transform_path='db_files/muongun/transformers.pkl', db_path= 'db_files/muongun/rasmus_classification_muon_3neutrino_3mio.db', return_eventnos=True)\n",
    "loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature = loader.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training = False)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "\n",
    "    return predictions, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        predictions, targets = test_step(inputs, targets)\n",
    "\n",
    "        prediction_list.append(predictions.numpy())\n",
    "        target_list.append(targets.numpy())\n",
    "        y_reco  = tf.concat(prediction_list, axis = 0).numpy()\n",
    "        y_true  = tf.concat(target_list, axis = 0)\n",
    "        y_true  = tf.cast(y_true, tf.float32).numpy()\n",
    "    return y_reco, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco, true=predict(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-657fa58a42c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreco_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'energy_log10_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zenith_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'azimuth_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zenith_sigma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'azimuth_sigma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrecos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreco_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### change azi/zeni sigma to real sig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "reco_str=['energy_log10_pred', 'zenith_pred', 'azimuth_pred', 'zenith_sigma', 'azimuth_sigma']\n",
    "recos=pd.DataFrame(reco)\n",
    "recos.columns=reco_str\n",
    "recos.head() ### change azi/zeni sigma to real sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get event_nos through data_load (just make an extra file with event_nos)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ee7ae0cce42568ffbe792829a147e8b26e32fc5929320da4cac6b0f8a68675f6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ee7ae0cce42568ffbe792829a147e8b26e32fc5929320da4cac6b0f8a68675f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}