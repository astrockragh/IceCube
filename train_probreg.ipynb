{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:32.952318Z",
     "start_time": "2021-03-04T13:12:32.940316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n",
      "GPU detected\n"
     ]
    }
   ],
   "source": [
    "import os, sys, argparse, importlib, time, inspect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    print('Notebook')\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    print('Not notebook')\n",
    "    from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"GPU detected\")\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('No GPU detected')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import spektral\n",
    "\n",
    "from spektral.data import DisjointLoader, BatchLoader, SingleLoader\n",
    "from importlib import reload\n",
    "import winsound\n",
    "import dill, wandb\n",
    "import datetime as dt\n",
    "wandblog=0\n",
    "if wandblog:\n",
    "    !wandb login b5b917a9390932e56fccfcbff6f528ccd85c44bf\n",
    "run_counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:33.274929Z",
     "start_time": "2021-03-04T13:12:33.267951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.4.1', '1.0.3')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, spektral.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:33.611158Z",
     "start_time": "2021-03-04T13:12:33.605206Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Setup Deafult Variables                       # \n",
    "################################################\n",
    "learning_rate = 1e-4\n",
    "batch_size    = 512\n",
    "epochs        = 20\n",
    "n_data       = 1e4\n",
    "scenario    = \"GAT_test\"+str(run_counter)\n",
    "patience = 20\n",
    "\n",
    "################################################\n",
    "# Setup Hyperparameters                        # \n",
    "################################################\n",
    "hidden_states = 'N/A'\n",
    "forward       = False\n",
    "dropout       = 'None'\n",
    "loss_method   = \"loss_func_linear_angle\"\n",
    "n_neighbors   = 6 # SKRIV SELV IND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:46.750367Z",
     "start_time": "2021-03-04T13:12:33.930232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed and ready to reload\n",
      "Connecting to db-file\n",
      "Loading Muons\n",
      "Reading files\n",
      "Splitting data to events\n",
      "Generating adjacency matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RobustScaler from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aab3fe9c9dd41628dcb5d177f60d796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Saving dataset\n",
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Load data                      # \n",
    "################################################\n",
    "\n",
    "import data_load as dl\n",
    "reload(dl)\n",
    "graph_data=dl.graph_data\n",
    "dataset=graph_data(n_data=n_data, restart=1, transform=True)\n",
    "idx_lists = dataset.index_lists\n",
    "# Split data\n",
    "dataset_train = dataset[idx_lists[0]]\n",
    "dataset_val   = dataset[idx_lists[1]]\n",
    "dataset_test  = dataset[idx_lists[2]]\n",
    "\n",
    "loader_train = DisjointLoader(dataset_train, epochs=epochs, batch_size=batch_size) # the different loaders work very very differently, beware\n",
    "loader_test = DisjointLoader(dataset_test, batch_size=batch_size, epochs=1)\n",
    "\n",
    "winsound.Beep(400,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:51:57.833855Z",
     "start_time": "2021-03-04T13:51:57.822847Z"
    }
   },
   "outputs": [],
   "source": [
    "from evals import metricsxpos as metrics\n",
    "\n",
    "def test_angle(loader, plot=True):\n",
    "    '''Function to test and plot performance of Graph DL\n",
    "    input should be dom pos x,y,z , time, charge(log10)\n",
    "    target should be energy(log10),zenith angle, azimuthal angle, NOT unit vec \n",
    "    '''\n",
    "    loss = 0\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        inputs[0][:, :3] = inputs[0][:, :3] / 1000 #always pay attention to these two normalizations\n",
    "        predictions, targets, out = test_step(inputs, targets)\n",
    "        loss           += out\n",
    "        \n",
    "        prediction_list.append(predictions)\n",
    "        target_list.append(targets)\n",
    "\n",
    "    y_reco  = tf.concat(prediction_list, axis = 0).numpy()\n",
    "    y_true  = tf.concat(target_list, axis = 0)\n",
    "    y_true  = tf.cast(y_true, tf.float32).numpy()\n",
    "\n",
    "    energy = y_true[:, 0]\n",
    "    counts, bins = np.histogram(energy, bins = 10)\n",
    "\n",
    "    xs = (bins[1:] + bins[: -1]) / 2\n",
    "\n",
    "    w_energies, u_angles = [], []\n",
    "\n",
    "    for i in range(len(bins)-1):\n",
    "        idx = np.logical_and(energy > bins[i], energy < bins[i + 1])\n",
    "\n",
    "        w, u_angle = metrics(y_true[idx, :], y_reco[idx, :])\n",
    "\n",
    "        w_energies.append(w)\n",
    "        u_angles.append(u_angle)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(ncols = 2, nrows = 1, figsize = (12, 6))\n",
    "\n",
    "        for a in ax:\n",
    "            a_ = a.twinx()\n",
    "            a_.step(xs, counts, color = \"gray\", zorder = 10, alpha = 0.7, where = \"mid\")\n",
    "            a_.set_yscale(\"log\")\n",
    "            a.set_xlabel(\"Log Energy\")\n",
    "        \n",
    "        ax_top = ax\n",
    "\n",
    "        # Energy reconstruction\n",
    "        ax_top[0].scatter(xs, w_energies)\n",
    "        ax_top[0].set_title(\"Energy Performance\")\n",
    "        ax_top[0].set_ylabel(r\"$w(\\Delta log(E)$\")\n",
    "\n",
    "        # Angle reconstruction\n",
    "        ax_top[1].scatter(xs, u_angles)\n",
    "        ax_top[1].set_title(\"Angle Performance\")\n",
    "        ax_top[1].set_ylabel(r\"$u(\\Delta \\Omega)$\")\n",
    "\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:51:57.988663Z",
     "start_time": "2021-03-04T13:51:57.983676Z"
    }
   },
   "outputs": [],
   "source": [
    "if wandblog:\n",
    "    #checks\n",
    "    wandb.init(project=\"icecube\", name=scenario,entity=\"chri862z\")\n",
    "\n",
    "    # Declare for log\n",
    "    wandb.config.hidden_states = hidden_states\n",
    "    wandb.config.hidden_states = n_data\n",
    "    wandb.config.forward = forward\n",
    "    wandb.config.dropout = dropout\n",
    "    wandb.config.learning_rate = learning_rate\n",
    "    wandb.config.batch_size = batch_size\n",
    "    wandb.config.loss_func = loss_method\n",
    "    wandb.config.n_neighbors = n_neighbors\n",
    "    wandb.config.optimizer = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:51:58.166414Z",
     "start_time": "2021-03-04T13:51:58.140446Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Load Model and do checks                      # \n",
    "################################################\n",
    "# import models.GCN0 as m\n",
    "import models.probreg_GCN as m\n",
    "reload(m)\n",
    "# model=m.GCN0(6)\n",
    "model=m.model()\n",
    "# model.compile('adam', 'categorical_crossentropy') ## this is a basic setup with predetermined optimizers and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T14:10:36.717535Z",
     "start_time": "2021-03-04T14:10:36.688591Z"
    }
   },
   "outputs": [],
   "source": [
    "# ################################################\n",
    "# # Setup functions                            # \n",
    "# ################################################\n",
    "import loss.loss_probreg as loss_funcs\n",
    "reload(loss_funcs)\n",
    "loss_func=loss_funcs.sig_likelihood\n",
    "\n",
    "def lr_schedule(epochs = epochs, initial = learning_rate, decay = 0.9):\n",
    "    n = 1\n",
    "    lr = initial\n",
    "    yield lr\n",
    "    while n < 3:\n",
    "        lr *= 2\n",
    "        n  += 1\n",
    "        yield lr\n",
    "    while True:\n",
    "        lr *= decay\n",
    "        n  += 1 \n",
    "        yield lr\n",
    "\n",
    "\n",
    "#make functions into tf functions\n",
    "\n",
    "@tf.function(input_signature = loader_train.tf_signature(), experimental_relax_shapes = True)\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        global predictionsval\n",
    "        predictions = model(inputs, training = True)\n",
    "        predictionsval=tf.cast(predictions, tf.float32) \n",
    "        targets     = tf.cast(targets, tf.float32)\n",
    "#         tf.print(tf.shape(predictions),tf.shape(targets))\n",
    "        loss        = loss_func(predictions, targets)\n",
    "        loss       += sum(model.losses)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function(input_signature = loader_test.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training = False)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "    out         = loss_func(predictions, targets)\n",
    "\n",
    "    return predictions, targets, out\n",
    "\n",
    "\n",
    "def validation(loader):\n",
    "    loss = 0\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        # inputs[0][:, :3] = inputs[0][:, :3] / 1000\n",
    "        # inputs[0][:, 3] = inputs[0][:, 3]\n",
    "        # targets[:, 1:4] = targets[:, 1:4] / 1000\n",
    "        predictions, targets, out = test_step(inputs, targets)\n",
    "        loss           += out\n",
    "        \n",
    "        prediction_list.append(predictions)\n",
    "        target_list.append(targets)\n",
    "    \n",
    "    y_reco  = tf.concat(prediction_list, axis = 0)\n",
    "    y_true  = tf.concat(target_list, axis = 0)\n",
    "    y_true  = tf.cast(y_true, tf.float32)\n",
    "    global losses\n",
    "    # w_energy, u_pos, u_angle = metrics(y_reco, y_true) #still missing something\n",
    "    loss, losses = loss_func(y_reco, y_true, re=True)\n",
    "\n",
    "    return loss, losses, metrics(y_reco, y_true)\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T14:10:52.204053Z",
     "start_time": "2021-03-04T14:10:36.987112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bbdb22bb37427fa2dc40361e5ba649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b676f169c74146a59438c45042492707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[320 3 3] [320 1 3]\n",
      "[320 3 3] [320 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "Epoch 1 of 20 done in 13.91 seconds using learning rate: 1.00E-04\n",
      "Avg loss of train: 8.582011\n",
      "[512 3 3] [512 1 3]\n",
      "[512 3 3] [512 3]\n",
      "[488 3 3] [488 1 3]\n",
      "[488 3 3] [488 3]\n",
      "[1000 3 3] [1000 1 3]\n",
      "[1000 3 3] [1000 3]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1000,65] vs. [1000,2] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-c1896263977e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mloader_val\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mDisjointLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#         val_loss, val_loss_from, val_metric = validation(loader_val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_from\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwandblog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             wandb.log({\"Train Loss\":      loss / loader_train.steps_per_epoch,\n",
      "\u001b[1;32m<ipython-input-103-17599c195a44>\u001b[0m in \u001b[0;36mvalidation\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_reco\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_reco\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Christian\\3YR-UNI\\Bachelor\\IceCube\\evals.py\u001b[0m in \u001b[0;36mmetricsxpos\u001b[1;34m(y_reco, y_true)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Angle metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mangle_resi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m180\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_reco\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#degrees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;31m# angle_resi = 180 / np.pi * tf.reduce_mean(angle(y_reco[:, 4:], y_true[:, 4:])) #degrees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Christian\\3YR-UNI\\Bachelor\\IceCube\\evals.py\u001b[0m in \u001b[0;36mangle\u001b[1;34m(pred, true)\u001b[0m\n\u001b[0;32m     10\u001b[0m     return tf.math.acos(\n\u001b[0;32m     11\u001b[0m         tf.clip_by_value(\n\u001b[1;32m---> 12\u001b[1;33m             tf.math.divide_no_nan(tf.reduce_sum(pred * true, axis = 1),\n\u001b[0m\u001b[0;32m     13\u001b[0m             tf.math.reduce_euclidean_norm(pred, axis = 1) * tf.math.reduce_euclidean_norm(true,  axis = 1)),\n\u001b[0;32m     14\u001b[0m             -1., 1.)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6066\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6067\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6068\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6069\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1000,65] vs. [1000,2] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "run_counter+=1\n",
    "k=0.2\n",
    "tot_time=0\n",
    "current_batch = 0\n",
    "current_epoch = 1\n",
    "loss          = 0\n",
    "lowest_loss   = np.inf\n",
    "early_stop    = 1\n",
    "early_stop_counter    = 0\n",
    "pbar0          = tqdm(total = epochs, position = 0, leave = True)\n",
    "pbar0.set_description(f\"Epochbar\")\n",
    "pbar          = tqdm(total = loader_train.steps_per_epoch, position = k, leave = True)\n",
    "start_time    = time.time()\n",
    "lr_gen        = lr_schedule(initial=learning_rate)\n",
    "learning_Rate = next(lr_gen)\n",
    "cwd = osp.abspath('')\n",
    "save_path = osp.join(cwd, 'trained_models/'+scenario)\n",
    "if not osp.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    print('New folder for saving '+scenario+' made')\n",
    "# Implement saving model archictecture to wandb\n",
    "for batch in loader_train:\n",
    "    inputs, targets = batch\n",
    "    inputs[0][:, :3] = inputs[0][:, :3] / 1000 #normalize position\n",
    "    out             = train_step(inputs, targets)\n",
    "    loss           += out\n",
    "#     if current_epoch==1 and current_batch==0:\n",
    "# #         model.summary()\n",
    "    \n",
    "    current_batch  += 1\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(f\"Epoch {current_epoch} / {epochs}; Avg_loss: {loss / current_batch:.6f}\")\n",
    "    \n",
    "    \n",
    "    if current_batch == loader_train.steps_per_epoch:\n",
    "        t=time.time() - start_time\n",
    "        tot_time+=t\n",
    "        print(f\"Epoch {current_epoch} of {epochs} done in {t:.2f} seconds using learning rate: {learning_rate:.2E}\")\n",
    "        print(f\"Avg loss of train: {loss / loader_train.steps_per_epoch:.6f}\")\n",
    "\n",
    "        loader_val    = DisjointLoader(dataset_val, epochs = 1,      batch_size = batch_size)\n",
    "#         val_loss, val_loss_from, val_metric = validation(loader_val)\n",
    "        val_loss, val_loss_from, val_metric = validation(loader_val)\n",
    "        if wandblog:\n",
    "            wandb.log({\"Train Loss\":      loss / loader_train.steps_per_epoch,\n",
    "                       \"Validation Loss\": val_loss, \n",
    "                       \"Energy metric\":   val_metric[0],\n",
    "                       \"Angle metric\":    val_metric[1],\n",
    "                       \"Learning rate\":   learning_rate})\n",
    "\n",
    "        print(f\"Avg loss of validation: {val_loss:.6f}\")\n",
    "        print(f\"Loss from:  Energy: {val_loss_from[0]:.6f} \\t Angle: {val_loss_from[1]:.6f} \")\n",
    "        print(f\"Energy: w = {val_metric[0]:.6f} \\t Angle: u = {val_metric[1]:.6f}\")\n",
    "\n",
    "        if val_loss < lowest_loss:\n",
    "            early_stop_counter = 0\n",
    "            lowest_loss        = val_loss\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        print(f'Early stop counter: {early_stop_counter}/{patience}, lowest loss was {lowest_loss:.6f}')\n",
    "        if early_stop and (early_stop_counter >= patience):\n",
    "            model.save(save_path)\n",
    "            print(f\"Stopped training. No improvement was seen in {patience} epochs\")\n",
    "            break\n",
    "\n",
    "        if current_epoch != epochs:\n",
    "            pbar          = tqdm(total = loader_train.steps_per_epoch, position = k, leave = True)\n",
    "\n",
    "        learning_rate = next(lr_gen)\n",
    "        opt.learning_rate.assign(learning_rate)\n",
    "        pbar0.update(1)\n",
    "        time_avg=tot_time/current_epoch\n",
    "        delta=dt.timedelta(seconds=time_avg*(epochs-current_epoch))\n",
    "        now = dt.datetime.now()\n",
    "        then=now+delta\n",
    "        time_e = then.strftime(\"%H:%M:%S\")\n",
    "        pbar0.set_description(f\"Expect to finish at {time_e}\")\n",
    "#         if current_epoch % 10 == 0:\n",
    "#             model.save(save_path)\n",
    "#             print(\"Model saved\")\n",
    "\n",
    "        loss            = 0\n",
    "        start_time      = time.time()\n",
    "        current_epoch  += 1\n",
    "        current_batch   = 0\n",
    "winsound.Beep(400,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:46.845680Z",
     "start_time": "2021-03-04T13:12:36.294Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = test_angle(loader_test)\n",
    "if wandblog:\n",
    "    fig.savefig(f\"model_tests/{scenario}_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:12:46.847675Z",
     "start_time": "2021-03-04T13:12:36.666Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Evaluating our model                 # \n",
    "################################################\n",
    "\n",
    "trainable_count = int(\n",
    "    np.sum([K.count_params(p) for p in model.trainable_weights]))\n",
    "non_trainable_count = int(\n",
    "    np.sum([K.count_params(p) for p in model.non_trainable_weights]))\n",
    "\n",
    "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T14:14:43.259296Z",
     "start_time": "2021-03-04T14:14:42.054354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.5621819  -0.8270136   0.45492536 ...  0.7533319   0.06258322\n",
      "   0.65969706]\n",
      " [ 0.5288799  -0.8486967   2.104484   ...  1.6576217   0.00905073\n",
      "   0.941267  ]\n",
      " [ 0.5087528  -0.8609127   0.8546529  ...  0.76553595  0.22838165\n",
      "   0.91031104]\n",
      " ...\n",
      " [ 0.47644016 -0.8792069   1.5868886  ...  1.211982    0.08758099\n",
      "   0.8337561 ]\n",
      " [ 0.5530459  -0.8331508   0.7767262  ...  0.91565657  0.04885986\n",
      "   0.7137921 ]\n",
      " [ 0.5379181  -0.8429971   1.0938455  ...  1.1507676   0.0143856\n",
      "   0.7810372 ]], shape=(512, 66), dtype=float32)\n",
      "0\n",
      "tf.Tensor(\n",
      "[[ 5.3968114e-01 -8.4186947e-01  7.3556215e-01 ...  9.1850841e-01\n",
      "   4.4340096e-02  6.5779239e-01]\n",
      " [ 5.4487377e-01 -8.3851808e-01  9.0674520e-01 ...  9.6494937e-01\n",
      "   1.0598631e-01  6.5970379e-01]\n",
      " [ 5.0768113e-01 -8.6154503e-01  2.2350392e+00 ...  1.7267858e+00\n",
      "   1.3991188e-01  8.8067931e-01]\n",
      " ...\n",
      " [ 5.3346878e-01 -8.4581971e-01  4.2787376e-01 ...  6.5759474e-01\n",
      "   4.2334303e-02  6.8938816e-01]\n",
      " [ 4.7935590e-01 -8.7762064e-01  1.1447527e-03 ...  4.4050694e-01\n",
      "   1.2724896e-01  5.0193775e-01]\n",
      " [ 5.4376870e-01 -8.3923513e-01  5.4869831e-01 ...  8.1220025e-01\n",
      "   5.8541976e-02  6.3160014e-01]], shape=(488, 66), dtype=float32)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "loader_val    = DisjointLoader(dataset_val, epochs = 1,      batch_size = batch_size)\n",
    "for i,batch in enumerate(loader_val):\n",
    "    inputs, targets = batch\n",
    "    predictions=model(inputs)\n",
    "    print(predictions)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T14:13:33.246936Z",
     "start_time": "2021-03-04T14:13:33.239958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(488, 66), dtype=float32, numpy=\n",
       "array([[ 0.53359705, -0.8457388 ,  1.5609174 , ...,  1.349319  ,\n",
       "         0.01543205,  0.7901085 ],\n",
       "       [ 0.51036775, -0.8599562 ,  2.224135  , ...,  1.6503104 ,\n",
       "         0.04791152,  0.9609264 ],\n",
       "       [ 0.47912487, -0.8777468 ,  0.10259184, ...,  0.51117367,\n",
       "         0.1419247 ,  0.50054836],\n",
       "       ...,\n",
       "       [ 0.57406366, -0.8188107 ,  1.2186431 , ...,  1.0840503 ,\n",
       "         0.05218859,  0.9712802 ],\n",
       "       [ 0.47296175, -0.88108295,  0.16127457, ...,  0.56065345,\n",
       "         0.06562333,  0.44658703],\n",
       "       [ 0.5698642 , -0.82173884,  0.7507787 , ...,  0.8312793 ,\n",
       "         0.08987123,  0.77896404]], dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
