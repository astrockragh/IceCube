{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:36:52.649140Z",
     "start_time": "2021-05-10T15:36:46.285104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n",
      "GPU detected\n",
      "Not notebook\n"
     ]
    }
   ],
   "source": [
    "import os, sys, argparse, importlib, time, inspect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    print('Notebook')\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    print('Not notebook')\n",
    "    from tqdm import tqdm\n",
    "from tensorflow.keras import backend as K\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"GPU detected\")\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('No GPU detected')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import spektral\n",
    "from sklearn.preprocessing import normalize\n",
    "from spektral.data import DisjointLoader, BatchLoader, SingleLoader\n",
    "from importlib import reload\n",
    "import winsound\n",
    "import dill\n",
    "import datetime as dt\n",
    "import from_config.dev.data_load as dl\n",
    "import wandb\n",
    "graph_data=dl.graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:36:58.721655Z",
     "start_time": "2021-05-10T15:36:52.867481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/cpu:0'): # if on the cpu\n",
    "batch_size=512\n",
    "dataset=graph_data(n_data=100000,         transform_path='db_files/muongun/transformers.pkl',\\\n",
    "             db_path= 'db_files/muongun/rasmus_classification_muon_3neutrino_3mio.db', n_neighbors=10, skip=int(1.4e6-1), restart=0)\n",
    "loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:37:47.821985Z",
     "start_time": "2021-05-10T15:37:47.801043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:01.615465Z",
     "start_time": "2021-05-08T14:22:01.572582Z"
    },
    "code_folding": [
     108,
     154
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from spektral.layers import GraphSageConv, MessagePassing\n",
    "from spektral.layers.pooling.global_pool import GlobalMaxPool, GlobalAvgPool, GlobalSumPool\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout, multiply\n",
    "from tensorflow.keras.activations import tanh, sigmoid\n",
    "from tensorflow.sparse import SparseTensor\n",
    "\n",
    "eps=1e-5\n",
    "\n",
    "print('loading model')\n",
    "\n",
    "d_act=LeakyReLU(alpha=0.15)\n",
    "\n",
    "def no_norm(x, training):\n",
    "  return x\n",
    "\n",
    "class KHist(Model):\n",
    "    def __init__(self,hist, n_out = 3, n_sigs=2, K=[1,2], agg_method='min', hidden_states=40, glob=True, conv_layers=2, conv_activation='relu', decode_layers=2, decode_activation=1, regularization=None, dropout=0.2, batch_norm=True, forward=True):\n",
    "        super().__init__()\n",
    "        self.hist=hist\n",
    "        self.n_out=n_out\n",
    "        self.n_sigs=n_sigs\n",
    "        self.hidden_states=hidden_states\n",
    "        self.conv_activation=conv_activation\n",
    "        self.forward=forward\n",
    "        self.dropout=dropout\n",
    "        self.glob=glob\n",
    "        self.Ks=K\n",
    "        self.agg_method=agg_method\n",
    "        self.conv_layers=conv_layers\n",
    "        self.regularize=regularization\n",
    "        if type(decode_activation)==str:\n",
    "          self.decode_activation=tf.keras.activations.get(decode_activation)\n",
    "        else:\n",
    "          self.decode_activation=d_act\n",
    "        self.batch_norm=batch_norm\n",
    "        # Define layers of the model\n",
    "\n",
    "        self.MPs      = [SGConv(hidden_states, hidden_states, K=K, agg_method=self.agg_method, dropout = dropout) for K in self.Ks]\n",
    "\n",
    "        self.GCNs    = [GraphSageConv(hidden_states*int(i), activation=self.conv_activation, kernel_regularizer=self.regularize) for i in 2*2**np.arange(self.conv_layers)]\n",
    "\n",
    "        self.Pool1   = GlobalMaxPool()\n",
    "        self.Pool2   = GlobalAvgPool()\n",
    "        self.Pool3   = GlobalSumPool()\n",
    "\n",
    "        self.decode  = [Dense(i * hidden_states) for i in  2*2**np.arange(decode_layers+1,1,-1)]\n",
    "        self.dropout_layers  = [Dropout(dropout) for i in range(len(self.decode))]\n",
    "        if self.batch_norm:\n",
    "          self.norm_layers  = [BatchNormalization() for i in range(len(self.decode))]\n",
    "        else:\n",
    "          self.norm_layers =  [no_norm for i in range(len(self.decode))]\n",
    "        \n",
    "        self.loge     = [Dense(hidden_states) for _ in range(2)]\n",
    "        self.loge_out = Dense(1)\n",
    "        self.angles     = [Dense(hidden_states) for _ in range(2)]\n",
    "        self.angles_out = Dense(2)\n",
    "        self.angle_scale= Dense(2)\n",
    "        if n_sigs > 0:\n",
    "          self.sigs      = [Dense(hidden_states) for i in range(2)]\n",
    "          self.sigs_out  = Dense(n_sigs)\n",
    "\n",
    "    def call(self, inputs, training = False):\n",
    "        x, a, i = inputs\n",
    "        glob_avg=tf.math.segment_mean(x,i)\n",
    "        glob_var=abs(tf.math.subtract(tf.math.segment_mean(multiply([x,x]),i),multiply([glob_avg, glob_avg])))\n",
    "        glob_max=tf.math.segment_max(x,i)\n",
    "        glob_min=tf.math.segment_min(x,i)\n",
    "        xglob=tf.concat([glob_avg, glob_var, glob_max, glob_min], axis=1)\n",
    "        a, e    = self.generate_edge_features(x, a)\n",
    "        for MP in self.MPs:\n",
    "          x = MP([x, a, e])\n",
    "        for conv in self.GCNs:\n",
    "          x=conv([x,a])\n",
    "        x1 = self.Pool1([x, i])\n",
    "        x2 = self.Pool2([x, i])\n",
    "        x3 = self.Pool3([x, i])\n",
    "        x = tf.concat([x1, x2, x3], axis = 1)\n",
    "        x=tf.concat([x, xglob], axis=1)\n",
    "        for decode_layer, dropout_layer, norm_layer in zip(self.decode, self.dropout_layers, self.norm_layers):\n",
    "          x = dropout_layer(x, training = training)\n",
    "          x = self.decode_activation(decode_layer(x))\n",
    "          x = norm_layer(x, training = training)\n",
    "                \n",
    "        x_loge = self.loge[0](x)\n",
    "        x_loge = self.loge[1](x_loge)\n",
    "        x_loge = self.loge_out(x_loge)\n",
    "\n",
    "        x_angles = self.angles[0](x)\n",
    "        x_angles = self.angles[1](x_angles)\n",
    "        x_angles = self.angles_out(x_angles)\n",
    "        zeniazi=sigmoid(self.angle_scale(x_angles))\n",
    "\n",
    "        if self.n_sigs > 0:\n",
    "          x_sigs  = self.sigs[0](x)\n",
    "          x_sigs  = self.sigs[1](x_sigs)\n",
    "          x_sigs  = tf.abs(self.sigs_out(x_sigs)) + eps\n",
    "        #could add correlation here \n",
    "        xs=tf.stack([x_loge[:,0], zeniazi[:,0]*np.pi, zeniazi[:,1]*2*np.pi], axis = 1)\n",
    "        if self.n_sigs > 0:\n",
    "          return tf.concat([xs, x_sigs], axis=1)\n",
    "        else:\n",
    "          return xs\n",
    "\n",
    "\n",
    "    def generate_edge_features(self, x, a):\n",
    "      send    = a.indices[:, 0]\n",
    "      receive = a.indices[:, 1]\n",
    "      \n",
    "      if self.forward == True:\n",
    "        forwards  = tf.gather(x[:, 3], send) <= tf.gather(x[:, 3], receive)\n",
    "\n",
    "        send    = tf.cast(send[forwards], tf.int64)\n",
    "        receive = tf.cast(receive[forwards], tf.int64)\n",
    "\n",
    "        a       = SparseTensor(indices = tf.stack([send, receive], axis = 1), values = tf.ones(tf.shape(send), dtype = tf.float32), dense_shape = tf.cast(tf.shape(a), tf.int64))\n",
    "\n",
    "      diff_x  = tf.subtract(tf.gather(x, receive), tf.gather(x, send))\n",
    "\n",
    "      dists   = tf.sqrt(\n",
    "        tf.reduce_sum(\n",
    "          tf.square(\n",
    "            diff_x[:, :3]\n",
    "          ), axis = 1\n",
    "        ))\n",
    "\n",
    "      vects = tf.math.divide_no_nan(diff_x[:, :3], tf.expand_dims(dists, axis = -1))\n",
    "\n",
    "      e = tf.concat([diff_x[:, 3:], tf.expand_dims(dists, -1), vects], axis = 1)\n",
    "\n",
    "      return a, e\n",
    "\n",
    "class SGConv(MessagePassing):\n",
    "    # note that the D^-1/2 norm is not implemented since it is irrelevant for us \n",
    "    def __init__(self, n_out, hidden_states, K=2, agg_method='sum', dropout = 0):\n",
    "\n",
    "        \"\"\"Agg_method supports \"sum\": scatter_sum,\n",
    "          \"mean\": scatter_mean,\n",
    "          \"max\": scatter_max,\n",
    "          \"min\": scatter_min,\n",
    "          \"prod\": scatter_prod\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_out = n_out\n",
    "        self.agg_method=agg_method\n",
    "        self.K=K\n",
    "        self.hidden_states = hidden_states\n",
    "        self.message_mlps = [MLP(hidden_states, hidden = hidden_states * 2, layers = 2, dropout = dropout) for _ in range(self.K)]\n",
    "        self.update_mlp  = MLP(hidden_states, hidden = hidden_states, layers = 2, dropout = dropout)\n",
    "\n",
    "\n",
    "    ##inverted structure since tf requires output func to be propagate\n",
    "    def prop_khop(self, x, a, k, e=None, training = False, **kwargs):\n",
    "        self.n_nodes = tf.shape(x)[0]\n",
    "        self.index_i = a.indices[:, 1]\n",
    "        self.index_j = a.indices[:, 0]\n",
    "\n",
    "        # Message\n",
    "        # print(x, a, e)\n",
    "        # msg_kwargs = self.get_kwargs(x, a, e, self.msg_signature, kwargs)\n",
    "        messages = self.message(x, a, k, e, training = training)\n",
    "\n",
    "        # Aggregate\n",
    "        # agg_kwargs = self.get_kwargs(x, a, e, self.agg_signature, kwargs)\n",
    "\n",
    "        ##  make own aggregate\n",
    "        embeddings = self.aggregate(messages, training = training)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def propagate(self, x, a, e, training=False):\n",
    "        for hop in range(self.K):\n",
    "          x=self.prop_khop(x,a, hop, e, training = training)\n",
    "        return self.update(x, training = training)\n",
    "\n",
    "    def message(self, x, a, k, e, training = False):\n",
    "        # print([self.get_i(x), self.get_j(x), e])\n",
    "        out = tf.concat([self.get_i(x), self.get_j(x), e], axis = 1)\n",
    "        out = self.message_mlps[k](out, training = training)\n",
    "        return out\n",
    "    \n",
    "    def update(self, embeddings, training = False):\n",
    "        out = self.update_mlp(embeddings, training = training)\n",
    "        return out\n",
    "    \n",
    "class MLP(Model):\n",
    "    def __init__(self, output, hidden=256, layers=2, batch_norm=True,\n",
    "                 dropout=0.0, activation='relu', final_activation=None):\n",
    "        super().__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.mlp = Sequential()\n",
    "        for i in range(layers):\n",
    "            # Linear\n",
    "            self.mlp.add(Dense(hidden if i < layers - 1 else output, activation = activation))\n",
    "            if dropout > 0:\n",
    "                self.mlp.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = False):\n",
    "        return self.mlp(inputs, training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:02.361648Z",
     "start_time": "2021-05-08T14:22:01.616463Z"
    }
   },
   "outputs": [],
   "source": [
    "model=KHist(hist=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T15:28:45.632716Z",
     "start_time": "2021-05-08T15:28:45.624775Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size, sig=1024, 0.04\n",
    "res=40\n",
    "loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)\n",
    "batch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T15:28:46.636745Z",
     "start_time": "2021-05-08T15:28:46.299078Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function(input_signature = loader.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training = False)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "\n",
    "    return predictions, targets\n",
    "\n",
    "def predict(loader):\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        predictions, targets = test_step(inputs, targets)\n",
    "\n",
    "        prediction_list.append(predictions.numpy())\n",
    "        target_list.append(targets.numpy())\n",
    "        y_reco  = tf.concat(prediction_list, axis = 0).numpy()\n",
    "        y_true  = tf.concat(target_list, axis = 0)\n",
    "        y_true  = tf.cast(y_true, tf.float32).numpy()\n",
    "    return y_reco, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:23:29.978994Z",
     "start_time": "2021-05-08T14:23:29.942126Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fd67150adb0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkdet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKDE_gauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKDE_gauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(loader)\n",
    "predictions, targets = test_step(inputs, targets)\n",
    "kdet=KDE_gauss(targets[:,1], sig=sig)\n",
    "kder=KDE_gauss(predictions[:,1], sig=sig)\n",
    "if batch==0:\n",
    "    kdetrue=RunningKDE(kdet)\n",
    "    kdepred=RunningKDE(kder)\n",
    "else:\n",
    "    kdetrue.update(kdet, batch)\n",
    "    kdepred.update(kder, batch)\n",
    "batch+=1\n",
    "tdist, rdist, xs= pdfs(kdetrue.kde, kdepred.kde)\n",
    "plt.plot(xs, rdist, label='reco')\n",
    "plt.plot(xs, tdist, label='true')\n",
    "plt.hist(targets[:,1].numpy(), bins=bins, density=1, alpha=0.4)\n",
    "plt.hist(predictions[:,1].numpy(), bins=bins, density=1, alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T15:28:55.491905Z",
     "start_time": "2021-05-08T15:28:51.402684Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KDE_gauss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-1abf916d85a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mkdet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKDE_gauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mkder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKDE_gauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KDE_gauss' is not defined"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(loader):\n",
    "    inputs, targets = batch\n",
    "    predictions, targets = test_step(inputs, targets)\n",
    "    kdet=KDE_gauss(targets[:,1], sig=sig)\n",
    "    kder=KDE_gauss(predictions[:,1], sig=sig)\n",
    "    if i==0:\n",
    "        kdetrue=RunningKDE(kdet)\n",
    "        kdepred=RunningKDE(kder)\n",
    "    else:\n",
    "        kdetrue.update(kdet, i)\n",
    "        kdepred.update(kder, i)\n",
    "    tdist, rdist, xs= pdfs(kdetrue.kde, kdepred.kde)\n",
    "    fig, ax=plt.subplots(figsize=(12,9))\n",
    "    ax.plot(xs, rdist, label='reco')\n",
    "    ax.plot(xs, tdist, label='true')\n",
    "    ax.hist(targets[:,1].numpy(), bins=bins, density=1, alpha=0.4)\n",
    "    ax.hist(predictions[:,1].numpy(), bins=bins, density=1, alpha=0.4);\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.579861Z",
     "start_time": "2021-05-08T14:21:53.720Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DisjointLoader(dataset, batch_size=batch_size, epochs=1)\n",
    "reco, true=predict(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.580859Z",
     "start_time": "2021-05-08T14:21:53.722Z"
    }
   },
   "outputs": [],
   "source": [
    "xs=np.linspace(0,np.pi/2,50)\n",
    "kder=KDE_gauss(reco[:,1], sig=sig)\n",
    "kdet=KDE_gauss(true[:,1], sig=sig)\n",
    "tdist=kdet.prob(xs)\n",
    "rdist=kder.prob(xs)\n",
    "plt.plot(xs, rdist, label='reco')\n",
    "plt.plot(xs, tdist, label='true')\n",
    "plt.hist(reco[:,1], bins=bins, density=1, alpha=0.4)\n",
    "plt.hist(true[:,1], bins=bins, density=1, alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.581857Z",
     "start_time": "2021-05-08T14:21:53.724Z"
    }
   },
   "outputs": [],
   "source": [
    "tdist1, rdist1, xs1= pdfs(kdetrue.kde, kdepred.kde)\n",
    "fig, ax=plt.subplots(figsize=(12,9))\n",
    "ax.plot(xs1, tdist1, label='true_loop')\n",
    "ax.plot(xs, tdist, label='true')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.582853Z",
     "start_time": "2021-05-08T14:21:53.725Z"
    }
   },
   "outputs": [],
   "source": [
    "mix = 0.3\n",
    "bimix = tfd.Mixture(\n",
    "  cat=tfd.Categorical(probs=[mix, 1.-mix]),\n",
    "  components=[\n",
    "    kder,\n",
    "    kdet,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.583850Z",
     "start_time": "2021-05-08T14:21:53.727Z"
    }
   },
   "outputs": [],
   "source": [
    "KL=tf.math.reduce_sum(tdist1*tf.math.log((tdist1/(tdist))))\n",
    "# tfd.kl_divergence(kdet, kder)\n",
    "KL, tf.keras.losses.KLD(tdist1, tdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.584848Z",
     "start_time": "2021-05-08T14:21:53.728Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xs, bimix.prob(xs))\n",
    "np.trapz(bimix.prob(xs), xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.594822Z",
     "start_time": "2021-05-08T14:21:53.742Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xs, (yr-yt)**2/np.std(yr-yt)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T14:22:03.595819Z",
     "start_time": "2021-05-08T14:21:53.744Z"
    }
   },
   "outputs": [],
   "source": [
    "np.trapz(np.abs(yr-yt)**2/np.std(yr-yt)**2, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:37:58.657774Z",
     "start_time": "2021-05-10T15:37:58.556697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "loading model\n"
     ]
    }
   ],
   "source": [
    "import from_config.dev.eval_model as evals\n",
    "performance_plot = evals.performance_vM2D\n",
    "\n",
    "import from_config.dev.metrics as met\n",
    "metrics=met.energy_angle_zeniazi\n",
    "\n",
    "import from_config.dev.models as models\n",
    "reload(models)\n",
    "model = models.KHop()\n",
    "\n",
    "import from_config.dev.loss_funcs as lf\n",
    "loss_func=lf.abs_vonMises2D_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:38:17.363213Z",
     "start_time": "2021-05-10T15:38:04.117155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.data import DisjointLoader\n",
    "from importlib import __import__\n",
    "\n",
    "cwd = osp.abspath('')\n",
    "\n",
    "# wandblog=True\n",
    "# batch_size=512\n",
    "# # Setup Log \n",
    "# run = wandb.init(project = 'newloss', entity = \"chri862z\", group='KDEtest',\\\n",
    "#                  reinit=True)\n",
    "\n",
    "################################################\n",
    "#   Load dataset                              #\n",
    "################################################\n",
    "from from_config.dev.data_load import graph_data\n",
    "#load dataset\n",
    "epochs      = 20\n",
    "batch_size  = 100\n",
    "\n",
    "dataset=graph_data(n_data=2e5,transform_path='db_files/muongun/transformers.pkl',\\\n",
    "             db_path= 'db_files/muongun/rasmus_classification_muon_3neutrino_3mio.db', n_neighbors=14, restart=0)\n",
    "\n",
    "idx_lists = dataset.index_lists\n",
    "# Split data\n",
    "dataset_train = dataset[idx_lists[0]]\n",
    "dataset_val   = dataset[idx_lists[1]]\n",
    "dataset_test  = dataset[idx_lists[2]]\n",
    "\n",
    "loader_train = DisjointLoader(dataset_train, epochs=epochs, batch_size=batch_size)\n",
    "loader_test = DisjointLoader(dataset_test, batch_size=batch_size, epochs=1)\n",
    "\n",
    "\n",
    " ###############################################\n",
    "#   Setup other run params                     #\n",
    "################################################\n",
    "\n",
    "early_stop  = 5\n",
    "patience    = 5\n",
    "val_epoch = 10\n",
    "\n",
    "# print('check')\n",
    "################################################\n",
    "#   Setup model, loss, lr schedule and metrics #\n",
    "################################################\n",
    "\n",
    "# Get model, metrics, lr_schedule and loss function\n",
    "\n",
    "def classic(lr, warm_up = 3, decay = 0.9):\n",
    "\n",
    "    def lr_schedule():\n",
    "        # Intial value\n",
    "        factor = lr * 1 / 2 ** warm_up\n",
    "        yield factor\n",
    "        \n",
    "        # Multiply with 2 first few round\n",
    "        for i in range(warm_up):\n",
    "            factor *= 2\n",
    "            yield factor\n",
    "\n",
    "        # Make an exponential decay\n",
    "        while True:\n",
    "            factor *= decay\n",
    "            yield factor\n",
    "\n",
    "    return lr_schedule\n",
    "\n",
    "lr_schedule=classic(1e-3)()\n",
    "\n",
    "# save_path=osp.join(model_path,wandb.run.name)\n",
    "\n",
    "# if not osp.isdir(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "#     print('New folder for saving run made')\n",
    "\n",
    "# Learning rate and optimizer\n",
    "learning_rate            = next(lr_schedule)\n",
    "opt           = Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:39:16.490273Z",
     "start_time": "2021-05-10T15:39:16.480301Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function()\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "class RunningKDE():\n",
    "#     @tf.function(experimental_relax_shapes = True)\n",
    "    def __init__(self):\n",
    "        self.k=1\n",
    "#     @tf.function(experimental_relax_shapes = True)\n",
    "    def initialize(self):\n",
    "        self.kde = tfd.Mixture(cat=tfd.Categorical(probs=[tf.cast(0.5, tf.float32), tf.cast(0.5, tf.float32)]),components=[self.kdenew,self.kdenew])\n",
    "#         self.kde.dtype=tf.float64\n",
    "#     @tf.function(experimental_relax_shapes = True)\n",
    "    def update(self, batch):\n",
    "        mix=1/(batch+1)\n",
    "        self.kde = tfd.Mixture(cat=tfd.Categorical(probs=[tf.cast(1-mix, tf.float32), tf.cast(mix, tf.float32)]),components=[self.kde,self.kdenew])\n",
    "#     @tf.function(experimental_relax_shapes = True)\n",
    "    def prob(self,r=(0,tf.constant(np.pi/2)), res=50):\n",
    "        xs=tf.linspace(tf.cast(r[0], dtype=tf.float32),tf.cast(r[1], dtype=tf.float32),res)\n",
    "        return self.kde.prob(xs)\n",
    "#     @tf.function(experimental_relax_shapes = True)\n",
    "    def KDE_gauss(self, x,  batch_size=100, sig=0.05):\n",
    "#         @tf.function(experimental_relax_shapes = True)\n",
    "        def f(x, sig):\n",
    "            tfd.Independent(tfd.Normal(\n",
    "            loc=x, scale=sig))\n",
    "        n = batch_size\n",
    "        self.kdenew = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(\n",
    "        probs=[1/n]*n),\n",
    "        components_distribution=f(x, sig))\n",
    "        \n",
    "#     @tf.function()\n",
    "#     def prob(self):\n",
    "#         self.kde.prob(1)\n",
    "#         return tf.constant([value])\n",
    "# pi=np.pi\n",
    "# def KLD(kdet, kder, r=(0,tf.constant(np.pi)/2), res=50):\n",
    "#     xs=tf.linspace(tf.cast(r[0], dtype=tf.float32),tf.cast(r[1], dtype=tf.float32),res)\n",
    "#     tdist=kdet.prob(xs)\n",
    "#     rdist=kder.prob(xs)\n",
    "#     return tf.math.reduce_sum(tdist*tf.math.log(tdist/rdist))\n",
    "\n",
    "# def pdfs(true, reco, r=(0,tf.constant(np.pi/2)), res=50):\n",
    "#     xs=tf.linspace(tf.cast(r[0], dtype=tf.float64),tf.cast(r[1], dtype=tf.float64),res, dtype=tf.float64)\n",
    "#     tdist=true.prob(xs)\n",
    "#     rdist=reco.prob(xs)\n",
    "#     return tdist, rdist, xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:39:16.955935Z",
     "start_time": "2021-05-10T15:39:16.949911Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function(experimental_relax_shapes = True )\n",
    "def loss_kld(reco, true, kdetrue, kdepred, i=0):\n",
    "#     tf.print(true, reco)\n",
    "    kdetrue.KDE_gauss(true[:,1])\n",
    "    kdepred.KDE_gauss(reco[:,1])\n",
    "    if i==0:\n",
    "        kdetrue.initialize()\n",
    "        kdepred.initialize()\n",
    "#         tf.print(i)\n",
    "    else:\n",
    "        kdetrue.update(i)\n",
    "        kdepred.update(i)\n",
    "    tf.print(kdetrue.kde._cat_probs(log_probs=1))\n",
    "#     tdist=kdetrue.prob()\n",
    "#     rdist=kdepred.prob(4)\n",
    "#     tdist, rdist=tf.Tensor([1], dtype=tf.float32), tf.Tensor([0], dtype=tf.float32)\n",
    "#     tdist, rdist=tf.constant([1], dtype=tf.float32), tf.constant([0.1], dtype=tf.float32)\n",
    "#     return tf.keras.losses.KLD(tdist, rdist)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:39:17.345960Z",
     "start_time": "2021-05-10T15:39:17.336981Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function(experimental_relax_shapes = True )\n",
    "# def loss_kld(reco, true):\n",
    "#     return tf.keras.losses.KLD(true[:,1], reco[:,1])\n",
    "# #     return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:39:17.690357Z",
     "start_time": "2021-05-10T15:39:17.671409Z"
    }
   },
   "outputs": [],
   "source": [
    "class keep_track():\n",
    "#         @tf.function(experimental_relax_shapes = True)\n",
    "        def __init__(self):\n",
    "            self.list=[]\n",
    "        def update(self, l):\n",
    "            self.list=tf.concat([self.list, l], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:40:10.154085Z",
     "start_time": "2021-05-10T15:40:09.125554Z"
    },
    "code_folding": [
     105
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1600 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "in user code:\n\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:100 call  *\n        return self.propagate(x, a, e)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:490 propagate  *\n        x=self.prop_khop(x,a, hop, e, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:478 prop_khop  *\n        messages = self.message(x, a, k, e, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:496 message  *\n        out = self.message_mlps[k](out, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:332 call  *\n        return self.mlp(inputs, training = training)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:786 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:389 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:786 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1207 call\n        return core_ops.dense(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\ops\\core.py:53 dense\n        outputs = gen_math_ops.mat_mul(inputs, kernel)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:5547 mat_mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:517 _apply_op_helper\n        values = ops.convert_to_tensor(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1992 _dense_var_to_tensor\n        return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1393 _dense_var_to_tensor\n        return self.value()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:565 value\n        return self._read_variable_op()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:672 _read_variable_op\n        result = read_and_set_handle()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:662 read_and_set_handle\n        result = gen_resource_variable_ops.read_variable_op(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:483 read_variable_op\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:517 _apply_op_helper\n        values = ops.convert_to_tensor(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1499 convert_to_tensor\n        raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\n    RuntimeError: Attempting to capture an EagerTensor without building a function.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-357ce9b4a304>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mout\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkdetrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkdepred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mloss\u001b[0m           \u001b[1;33m+=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-357ce9b4a304>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(inputs, targets, kdetrue, kdepred, i)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkdetrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkdepred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtargets\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    829\u001b[0m           with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    830\u001b[0m               self._compute_dtype_object):\n\u001b[1;32m--> 831\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_edge_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mMP\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMPs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m           \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCNs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    785\u001b[0m                   self._compute_dtype_object):\n\u001b[1;32m--> 786\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: in user code:\n\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:100 call  *\n        return self.propagate(x, a, e)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:490 propagate  *\n        x=self.prop_khop(x,a, hop, e, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:478 prop_khop  *\n        messages = self.message(x, a, k, e, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:496 message  *\n        out = self.message_mlps[k](out, training = training)\n    C:\\Users\\chris\\Christian\\3YR-UNI\\Bachelor\\IceCube\\from_config\\dev\\models.py:332 call  *\n        return self.mlp(inputs, training = training)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:786 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:389 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:786 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1207 call\n        return core_ops.dense(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\ops\\core.py:53 dense\n        outputs = gen_math_ops.mat_mul(inputs, kernel)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:5547 mat_mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:517 _apply_op_helper\n        values = ops.convert_to_tensor(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1992 _dense_var_to_tensor\n        return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1393 _dense_var_to_tensor\n        return self.value()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:565 value\n        return self._read_variable_op()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:672 _read_variable_op\n        result = read_and_set_handle()\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:662 read_and_set_handle\n        result = gen_resource_variable_ops.read_variable_op(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:483 read_variable_op\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:517 _apply_op_helper\n        values = ops.convert_to_tensor(\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\chris\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1499 convert_to_tensor\n        raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\n    RuntimeError: Attempting to capture an EagerTensor without building a function.\n"
     ]
    }
   ],
   "source": [
    "wandblog=0\n",
    "\n",
    "################################################\n",
    "#   Set up TF functions and validation step   #\n",
    "################################################\n",
    "\n",
    "# Define training function\n",
    "# @tf.function(input_signature = loader_train.tf_signature(), experimental_relax_shapes = True)\n",
    "TensorSpec=tf.TensorSpec\n",
    "TensorShape=tf.TensorShape\n",
    "SparseTensorSpec=tf.SparseTensorSpec\n",
    "new_sig=(((TensorSpec(shape=(None, 6), dtype=tf.float64, name=None),\n",
    "   SparseTensorSpec(TensorShape([None, None]), tf.float64),\n",
    "   TensorSpec(shape=(None,), dtype=tf.int64, name=None)),\n",
    "  TensorSpec(shape=(None, 3), dtype=tf.float64, name=None),\n",
    " TensorSpec(shape=(), dtype=tf.int32, name=None)))\n",
    "keep=keep_track()\n",
    "# @tf.function(input_signature = new_sig, experimental_relax_shapes = True)\n",
    "# @tf.function(experimental_relax_shapes = True)\n",
    "def train_step(inputs, targets, kdetrue, kdepred, i):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training = True)\n",
    "        targets     = tf.cast(targets, tf.float32)\n",
    "        loss        = loss_func(predictions, targets)\n",
    "#         keep.update(targets[:,1])\n",
    "#         loss       +=loss_kld(predictions, targets)\n",
    "        loss1       =loss_kld(predictions, targets, kdetrue,kdepred, i)\n",
    "        kdetrue.kde.prob(1)\n",
    "        loss       += sum(model.losses)\n",
    "#         tf.print(i)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# @tf.function(input_signature = loader_test.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training = False)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "\n",
    "    return predictions, targets, out\n",
    "\n",
    "\n",
    "def validation(loader):\n",
    "    loss = 0\n",
    "    prediction_list, target_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch\n",
    "        predictions, targets, out = test_step(inputs, targets)\n",
    "        loss           += out\n",
    "\n",
    "        prediction_list.append(predictions)\n",
    "        target_list.append(targets)\n",
    "\n",
    "    y_reco  = tf.concat(prediction_list, axis = 0)\n",
    "    y_true  = tf.concat(target_list, axis = 0)\n",
    "    y_true  = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    loss, loss_from = loss_func(y_reco, y_true, re=True)\n",
    "\n",
    "    energy, e_old, alpha, zeni, azi= metrics(y_reco, y_true)\n",
    "\n",
    "    return loss, loss_from, [energy, e_old, alpha, zeni, azi]\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "#  Train Model                                 #      \n",
    "################################################\n",
    "\n",
    "kdetrue=RunningKDE()\n",
    "kdepred=RunningKDE()\n",
    "\n",
    "tot_time=0\n",
    "current_batch = 0\n",
    "current_epoch = 1\n",
    "loss          = 0\n",
    "lowest_loss   = np.inf\n",
    "early_stop    = 1\n",
    "early_stop_counter    = 0\n",
    "pbar          = tqdm(total = loader_train.steps_per_epoch, position=0, leave = True)\n",
    "start_time    = time.time()\n",
    "summarylist=[]\n",
    "for i, batch in enumerate(loader_train):\n",
    "    i=tf.cast(i, tf.int32)\n",
    "    \n",
    "    inputs, targets = batch\n",
    "    out             = train_step(inputs, targets, kdetrue, kdepred, i=i)\n",
    "    loss           += out\n",
    "    if current_epoch==1 and current_batch==0:\n",
    "        model.summary()\n",
    "        if wandblog:\n",
    "            summary=model.summary(print_fn=summarylist.append)\n",
    "            table=wandb.Table(columns=[\"Layers\"])\n",
    "            for s in summarylist:\n",
    "                table.add_data(s)\n",
    "            wandb.log({'Model summary': table})\n",
    "    current_batch  += 1\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(f\"Epoch {current_epoch} / {epochs}; Avg_loss: {loss / current_batch:.6f}\")\n",
    "\n",
    "    if current_batch == loader_train.steps_per_epoch:\n",
    "        t=time.time() - start_time\n",
    "        tot_time+=t\n",
    "        print(f\"Epoch {current_epoch} of {epochs} done in {t:.2f} seconds using learning rate: {learning_rate:.2E}\")\n",
    "        print(f\"Avg loss of train: {loss / loader_train.steps_per_epoch:.6f}\")\n",
    "\n",
    "        loader_val    = DisjointLoader(dataset_val, epochs = 1,      batch_size = batch_size)\n",
    "        val_loss, val_loss_from, val_metric = validation(loader_val)\n",
    "        if wandblog:\n",
    "            wandb.log({\"Train Loss\":      loss / loader_train.steps_per_epoch,\n",
    "                    \"Validation Loss\": val_loss, \n",
    "                    \"w(log(E))\":   val_metric[1],\n",
    "                    \"Energy bias\":   val_metric[0][1],\n",
    "                    \"Energy sig-1\":   val_metric[0][0],\n",
    "                    \"Energy sig+1\":   val_metric[0][2],\n",
    "                    \"Solid angle 68th\":    val_metric[2][3],\n",
    "                    \"Angle bias\":   val_metric[2][1],\n",
    "                    \"Angle sig-1\":   val_metric[2][0],\n",
    "                    \"Angle sig+1\":   val_metric[2][2],\n",
    "                    \"zenith 68th\":    val_metric[3][3],\n",
    "                    \"zenith bias\":   val_metric[3][1],\n",
    "                    \"zenith sig-1\":   val_metric[3][0],\n",
    "                    \"zenith sig+1\":   val_metric[3][2],\n",
    "                    \"azimuth 68th\":    val_metric[4][3],\n",
    "                    \"azimuth bias\":   val_metric[4][1],\n",
    "                    \"azimuth sig-1\":   val_metric[4][0],\n",
    "                    \"azimuth sig+1\":   val_metric[4][2],\n",
    "                    \"Learning rate\":   learning_rate})\n",
    "        print(\"\\n\")\n",
    "        if not construct_dict['run_params']['zeniazi_metric']:\n",
    "            print(f\"Avg loss of validation: {val_loss:.6f}\")\n",
    "            print(f\"Loss from:  Energy: {val_loss_from[0]:.6f} \\t Angle: {val_loss_from[1]:.6f} \")\n",
    "            print(f\"Energy: bias = {val_metric[0][1]:.6f} sig_range = {val_metric[0][0]:.6f}<->{val_metric[0][2]:.6f}, old metric {val_metric[1]:.6f}\\\n",
    "                \\n Angle: bias = {val_metric[2][1]:.6f} sig_range = {val_metric[2][0]:.6f}<->{val_metric[2][2]:.6f}, old metric {val_metric[2][3]:.6f}\")\n",
    "        else:\n",
    "            print(f\"Avg loss of validation: {val_loss:.6f}\")\n",
    "            print(f\"Loss from:  Energy: {val_loss_from[0]:.6f} \\t Angle: {val_loss_from[1]:.6f} \")\n",
    "            print(f\"Energy: bias = {val_metric[0][1]:.6f} sig_range = {val_metric[0][0]:.6f}<->{val_metric[0][2]:.6f}, old metric {val_metric[1]:.6f}\\\n",
    "                \\n Angle: bias = {val_metric[2][1]:.6f} sig_range = {val_metric[2][0]:.6f}<->{val_metric[2][2]:.6f}, old metric {val_metric[2][3]:.6f}\\\n",
    "                \\n Zenith: bias = {val_metric[3][1]:.6f} sig_range = {val_metric[3][0]:.6f}<->{val_metric[3][2]:.6f}, old metric {val_metric[3][3]:.6f}\\\n",
    "                \\n Azimuth: bias = {val_metric[4][1]:.6f} sig_range = {val_metric[4][0]:.6f}<->{val_metric[4][2]:.6f}, old metric {val_metric[4][3]:.6f}\")\n",
    "\n",
    "        if val_loss < lowest_loss:\n",
    "            early_stop_counter = 0\n",
    "            lowest_loss        = val_loss\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        print(f'Early stop counter: {early_stop_counter}/{patience}, lowest val loss was {lowest_loss:.6f}')\n",
    "        if early_stop and (early_stop_counter >= patience):\n",
    "            print(f\"Stopped training. No improvement was seen in {patience} epochs\")\n",
    "\n",
    "        if current_epoch != epochs:\n",
    "            pbar          = tqdm(total = loader_train.steps_per_epoch, position=0, leave = True)\n",
    "\n",
    "        learning_rate = next(lr_schedule)\n",
    "        opt.learning_rate.assign(learning_rate)\n",
    "\n",
    "        time_avg=tot_time/current_epoch\n",
    "        if current_epoch % val_epoch == 0:\n",
    "            model.save(save_path)\n",
    "            print(\"Model saved\")\n",
    "            if wandblog:\n",
    "                loader_test = DisjointLoader(dataset_test, batch_size=batch_size, epochs=1)\n",
    "                fig, _ = performance_plot(loader_test, test_step, metrics, save=True, save_path=save_path)\n",
    "                title=\"performanceplot_\"+str(current_epoch)\n",
    "                wandb.log({title: [wandb.Image(fig, caption=title)]})\n",
    "\n",
    "        loss            = 0\n",
    "        start_time      = time.time()\n",
    "        current_epoch  += 1\n",
    "        current_batch   = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T16:33:46.269367Z",
     "start_time": "2021-05-08T16:33:45.080Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kdetrue.kde.prob(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
