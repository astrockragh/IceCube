{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall structure to understand what the hell is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T21:59:11.588198Z",
     "start_time": "2021-02-10T21:59:06.996986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sqlite3, pickle, sys, gzip, shutil, time\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "\n",
    "from pandas import read_sql, concat\n",
    "from sklearn.preprocessing import normalize, RobustScaler\n",
    "from sklearn.neighbors import kneighbors_graph as knn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from spektral.data import Dataset, Graph\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"GPU detected\")\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('No GPU detected')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "from spektral.data import DisjointLoader, BatchLoader\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:05.694639Z",
     "start_time": "2021-02-10T22:24:04.451779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to memory\n"
     ]
    }
   ],
   "source": [
    "import data_load as dl\n",
    "reload(dl)\n",
    "dataset=dl.graph_w_edge2()\n",
    "\n",
    "idx_lists = dataset.index_lists\n",
    "# Split data\n",
    "dataset_train = dataset[idx_lists[0]]\n",
    "dataset_val   = dataset[idx_lists[1]]\n",
    "dataset_test  = dataset[idx_lists[2]]\n",
    "\n",
    "loader = BatchLoader(dataset_train, batch_size=32) # the different loaders work very very differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:05.702620Z",
     "start_time": "2021-02-10T22:24:05.696634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:06.458724Z",
     "start_time": "2021-02-10T22:24:06.451742Z"
    }
   },
   "outputs": [],
   "source": [
    "from spektral.layers.convolutional.gcn_conv import GCNConv\n",
    "\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "import tensorflow as tf\n",
    "\n",
    "from spektral.layers import ECCConv\n",
    "from spektral.layers.pooling.global_pool import GlobalMaxPool \n",
    "from spektral.layers.pooling.global_pool import GlobalSumPool \n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.sparse import SparseTensor\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from spektral.layers import GCNConv, GlobalSumPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:07.361538Z",
     "start_time": "2021-02-10T22:24:07.352560Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyFirstGNN(Model):\n",
    "\n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense = Dense(n_labels, 'softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.graph_conv(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dense(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:08.214097Z",
     "start_time": "2021-02-10T22:24:08.188156Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MyFirstGNN(32, dataset.n_labels)\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:24:46.413063Z",
     "start_time": "2021-02-10T22:24:08.649719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 4s 13ms/step - loss: -47.5794\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: -248.6238\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: -771.3811\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: -1716.5761: 0s - loss: -168\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 3s 14ms/step - loss: -3085.8470: 0s - loss\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: -4884.6363 - ET\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: -6809.7529\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: -9169.4922\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: -11698.2787\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 3s 13ms/step - loss: -14850.7088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285d1499070>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:30:32.019121Z",
     "start_time": "2021-02-10T22:30:31.638734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: -15469.1465\n",
      "Test loss: -15469.146484375\n"
     ]
    }
   ],
   "source": [
    "loader = BatchLoader(dataset_test, batch_size=32)\n",
    "loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
    "\n",
    "print('Test loss: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:30:43.607366Z",
     "start_time": "2021-02-10T22:30:43.602345Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function(input_signature = loader.tf_signature(), experimental_relax_shapes = True)\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs)\n",
    "    targets     = tf.cast(targets, tf.float32) \n",
    "    out         = loss_func(predictions, targets)\n",
    "\n",
    "    return predictions, targets, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:30:44.491427Z",
     "start_time": "2021-02-10T22:30:44.481332Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs, targets =next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:33:33.804547Z",
     "start_time": "2021-02-10T22:33:33.783562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 7), dtype=float32, numpy=\n",
       "array([[0.00000000e+00, 0.00000000e+00, 2.46657121e-36, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.28962942e-12, 0.00000000e+00,\n",
       "        1.30242120e-06, 1.48038753e-05, 9.99983907e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.94830310e-01, 0.00000000e+00,\n",
       "        1.76646375e-20, 2.95874896e-32, 5.16965799e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.36662197e-04, 0.00000000e+00,\n",
       "        1.16153211e-25, 0.00000000e+00, 9.99663353e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.96743338e-02, 0.00000000e+00,\n",
       "        2.62215219e-22, 1.56837091e-37, 9.40325677e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.10822339e-05, 0.00000000e+00,\n",
       "        3.08649262e-19, 5.74929751e-29, 9.99988914e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.78297491e-09, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.40058464e-20, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.78825383e-26, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.85840722e-28, 0.00000000e+00,\n",
       "        2.45732158e-35, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.07290669e-29, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.32284206e-14, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.77946556e-27, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.88391561e-06, 0.00000000e+00,\n",
       "        2.38253095e-04, 1.68880288e-05, 9.99741971e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.45496184e-29, 0.00000000e+00,\n",
       "        3.07403451e-20, 3.40010735e-25, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.28105085e-14, 0.00000000e+00,\n",
       "        5.52687678e-04, 8.20060968e-02, 9.17441189e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.10950209e-18, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.89313928e-16, 0.00000000e+00,\n",
       "        4.94269796e-31, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.25700651e-21],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.29196601e-35, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 7.52926429e-18, 0.00000000e+00,\n",
       "        2.61914284e-33, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.16257019e-18, 0.00000000e+00,\n",
       "        2.61538219e-23, 4.22421738e-30, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.46286105e-33, 3.49668821e-14, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.85765477e-25, 1.08494296e-23, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.72400185e-28, 0.00000000e+00,\n",
       "        3.39885995e-34, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T22:31:17.356632Z",
     "start_time": "2021-02-10T22:31:17.352680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method test_step in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "test_step(data) method of __main__.MyFirstGNN instance\n",
      "    The logic for one evaluation step.\n",
      "    \n",
      "    This method can be overridden to support custom evaluation logic.\n",
      "    This method is called by `Model.make_test_function`.\n",
      "    \n",
      "    This function should contain the mathematical logic for one step of\n",
      "    evaluation.\n",
      "    This typically includes the forward pass, loss calculation, and metrics\n",
      "    updates.\n",
      "    \n",
      "    Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      "    `tf.distribute.Strategy` settings), should be left to\n",
      "    `Model.make_test_function`, which can also be overridden.\n",
      "    \n",
      "    Arguments:\n",
      "      data: A nested structure of `Tensor`s.\n",
      "    \n",
      "    Returns:\n",
      "      A `dict` containing values that will be passed to\n",
      "      `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      "      values of the `Model`'s metrics are returned.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.test_step)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
